---
title: "Project 3"
author: "Kassandra Sellers and Clark Necciai"
date: "2024-06-22"
output: html_document
---

1. Perform Data Prep (remove duplicate values)
2. Perform EDA 
3. Prepare Data for Modeling
4. Show some analysis on matrix form of ratings
5. Modeling 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 6, fig.height = 3)
```

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(reshape2)
library(dplyr)
library(visdat)
library(arules)
library(recommenderlab)
```

```{r}
#reading in the data
books_df = read.csv("Books.csv")
ratings_df = read.csv("Ratings.csv")
```

```{r}
#Observe Books Data
books_df %>% glimpse()
```

```{r}
#Observe Ratings Data
ratings_df %>% glimpse()
```

### Data Preprocessing

#### Missing Values  

```{r}
#Some missing values in original_publication_year, however, since we're 
#not doing any modeling with it, it can safely be ignored. 

print("Books Dataframe Missingness Percentages")
#Each variable's percentage of missing values
colSums(is.na(books_df)) / nrow(books_df) * 100

print("Ratings Dataframe Missingness Percentages")
#Each variable's percentage of missing values
colSums(is.na(ratings_df)) / nrow(ratings_df) * 100
```

#### Duplicate Observations

```{r}
#Observations and Their Duplicates
duplicated = which(duplicated(books_df$title))

#Show both the original observation and any duplicates
dup_obs = books_df[which(books_df$title %in% books_df$title[duplicated]),]
dup_obs %>% select(book_id, title, authors) %>% arrange(title)
```

```{r}
#Some observations have either 2, 3, or even 4 multiple duplicates  
rows_to_remove <- dup_obs %>% 
  group_by(title) %>% 
  summarise(count = n(), 
            .groups = 'drop') %>% 
  filter(count > 1) %>% 
  summarise(total_rows_to_remove = sum(count - 1))

print(paste("Total Number of Rows to be Removed: ", rows_to_remove))
```

```{r}
#Remove Duplicates from books_df where duplicate book titles
books_df = books_df %>% distinct(title, .keep_all = TRUE)

#Remove Duplicates from ratings_df where a user rated the same book twice
ratings_df = ratings_df %>% distinct(book_id, user_id, .keep_all = TRUE)

#Only retain ratings for which there is a reference to in Books Dataset
ratings_df = ratings_df[which(ratings_df$book_id %in% books_df$book_id),]

#Retrieve user_id values for users with at least 100 ratings
retained_users = ratings_df %>% 
    group_by(user_id) %>%
    summarise(count_ratings = n()) %>%
    filter(count_ratings >= 100) %>% 
    distinct(user_id)

#Retain Ratings for users with at least 100 ratings
ratings_df = ratings_df[ratings_df$user_id %in% retained_users$user_id,]

#Final Dimensionality of Books Dataframe
print(paste("Final Number of Observations (Books): ", dim(books_df)[1]))

#Final Number of Observations of Ratings Dataframe
print(paste("Final Number of Observations (Ratings): ",dim(ratings_df)[1]))
```

### Exploratory Data Analysis 

#### Summary Statistics 

```{r}
books_df %>% select(original_publication_year, average_rating, ratings_count, text_reviews_count,ratings_1, ratings_2, ratings_3, ratings_4, ratings_5) %>% summary()
```

```{r}
#Oldest Books in Repository
books_df[books_df$original_publication_year < -500 & !is.na(books_df$original_publication_year),] %>% 
  arrange((original_publication_year)) %>% 
  select(title, original_publication_year, authors)
```

#### Distribution of Ratings

```{r message=FALSE, warning=FALSE}
#As people hear about a book's popularity, they may be inclined to read and give feedback 

#Subset ratings for Density Plot
vars_to_plot <- c("ratings_1", "ratings_2", "ratings_3", "ratings_4", "ratings_5")
df_subset <- books_df[, vars_to_plot]
df_long <- melt(df_subset)

# Create density plot using ggplot
ggplot(df_long, aes(x = value, fill = variable)) +
  geom_density( alpha = 0.5) +
  theme_minimal() +
  labs(title = "Distribution of Ratings", 
       subtitle = "People Appear to Give Fewer Ratings for Poor Quality Books",
       x = "Number of Ratings", 
       y = "Density",
       fill = "Rating Score")  +
  scale_x_continuous(limits = c(-50, 12500))
```


#### Highest Rated Books (title) 

```{r fig.height=2}
books_df %>% 
  arrange(desc(average_rating)) %>% 
  select(book_id, title, average_rating, authors) %>% 
  head(5) %>%
  ggplot(aes(x = reorder(title, average_rating), y = average_rating)) +
  geom_col(aes(fill = average_rating), color = "black") +
  coord_flip() +
  geom_text(aes(label = average_rating), hjust = 1.5, color = "white") +
  labs(x = "Book Title",
       y = "Average Rating",
       title = "Top 5 Highest Rated Books") +
  theme(legend.position = "none")
```


#### Highest Rated Authors (author) 

```{r fig.height=2}
books_df %>% group_by(authors) %>%
  summarise(count_books_written = n(),
            average_rating = mean(average_rating, na.rm = T)) %>%
  filter(count_books_written > 5) %>%
  arrange(desc(average_rating)) %>% 
  head(5) %>%
  ggplot(aes(x = reorder(authors, average_rating), y = average_rating)) +
  geom_col(aes(fill = average_rating), color = "black") +
  coord_flip() +
  geom_text(aes(label = round(average_rating,2)), hjust = 1.5, color = "white") +
  labs(x = "Authors",
       y = "Average Rating",
       title = "Top 5 Highest Rated Authors",
       subtitle = "Must have Written More than Five (5) Published Books") +
  theme(legend.position = "none")
```


### Recommendation System Modeling 

#### Create Utility Matrix

```{r}
#Dimensionality of Sparse Matrix
count_unique_users <- ratings_df$user_id %>% n_distinct()
count_unique_books <- ratings_df$book_id %>% n_distinct()
print(paste("Unique Users Considered:", count_unique_users))
print(paste("Unique Books Considered:", count_unique_books))

#Sparsity of Matrix
perc = 100 * dim(ratings_df)[1] / (count_unique_users * count_unique_books)
print(paste("Matrix Percentage with Ratings: ", round(perc, 2) ))
```

```{r}
#Creating utility matrix (users as rows, movies as columns, ratings as entries)
ratingmat = spread(select(ratings_df, user_id, book_id, rating), book_id, rating)
ratingmat = as.matrix(ratingmat[,-1])

#Set Row and Column Labels to be respective User Ids and Book Titles
user_labels = sort(unique(ratings_df$user_id))
book_titles = books_df[match(as.numeric(colnames(ratingmat)),books_df$book_id),]$title
dimension_names = list(userId = user_labels, movieId = book_titles)
#Replace Book Ids with Book Titles
dimnames(ratingmat) = dimension_names
ratingmat[1:5,1:3]
```

#### Utility Matrix Visualization and Exploration

```{r}
#Converting rating/utility matrix to realRatingMatrix to use with recommenderlab functions
ratingMatrix = as(ratingmat, "realRatingMatrix")
#Inspection of rating matrix: It appears as though that as we get further into the database, books that were added
#last had fewer ratings as a whole. As book id >> then num ratings gets fewer
#Visual inspection of a small portion of the rating matrix (first 50 users, first 100 books)
image(ratingMatrix[1:nrow(ratingMatrix),1:ncol(ratingMatrix)], main = "Raw Ratings")
```

```{r}
#Number of submitted reviews - Left Skewed (Sudden Rise around 180-195)
count_ratings = rowCounts(ratingMatrix[1:nrow(ratingMatrix),])
med_num_ratings = median(count_ratings, na.rm = T)
hist(count_ratings, breaks = 15, main = "Number of Submitted Ratings by All Users")
mtext((paste("Median Number of Submitted Ratings: ", med_num_ratings)),
      side = 3, line = .8, cex = 0.8)
abline(v = med_num_ratings, col = "red", lty = 2)
```


```{r fig.width=8}
#Group Visualizations
par(mfrow = c(1,2))

#Average Rating of Each User
avg_user_rating = rowMeans(ratingMatrix[,])
median_rating = median(avg_user_rating)
hist(avg_user_rating, main = "Average Rating by All Users", xlab = "Average Rating")
mtext((paste("Median Rating by All Users: ", round(median_rating,2 ))),
      side = 3, line = .7, cex = 0.7)
abline(v = median_rating, col = "red", lty = 2)

#Average Rating of Each Book
avg_book_rating = colMeans(ratingMatrix[,1:ncol(ratingMatrix)], na.rm = T)
median_rating = median(avg_book_rating)
hist(avg_book_rating, main = "Average Rating of All Books", xlab = "Average Rating")
mtext((paste("Median Rating of All Books: ", round(median_rating,2 ))),
      side = 3, line = .7, cex = 0.7)
abline(v = median_rating, col = "red", lty = 2)
```

### Modeling

#### User-based collaborative filtering

```{r}
recUB = Recommender(ratingMatrix[-1,],"UBCF",
                    param = list(method="cosine",nn = 10))
```

```{r}
#recommendations for the first user (top 5)
predUBTOP = predict(recUB,ratingMatrix[1,],n=5)
as(predUBTOP,'list')
```

```{r}
#recommendations for the first user (predicted ratings of the movies not rated by the user)
predUB = predict(recUB,ratingMatrix[1,],type="ratings")
as(predUB,'list')
```

```{r}
#Optional: storing predicted ratings in a data frame
predictedUB_ratings = as(predUB,'data.frame') 
predictedUB_ratings %>% arrange(desc(rating))
```

#### Item-based collaborative filtering

```{r}
########### Item-based collaborative filtering model (IBCF):
#k: number of nearest items considered in making the recommendations
#method: the similarity measure, 'cosine' or 'pearson'
#(excluding the first user from training)
recIB = Recommender(ratingMatrix[-1,],"IBCF",
                    param = list(method="pearson",k=10))
```

```{r}
#recommendations for the first user (top 5)
predIBTOP = predict(recIB,ratingMatrix[1,],n=5)
as(predIBTOP,'list')
```

```{r}
#recommendations for the first user (predicted ratings of the movies not rated by the user)
predIB = predict(recIB,ratingMatrix[1,],type="ratings")
as(predIB,'list')
```

```{r}
#Optional: storing predicted ratings in a data frame
predictedIB_ratings = as(predIB,'data.frame') 
```

Comparing the models

```{r}
#Example 1:
#Here we're doing 5-fold CV, one rating is kept as holdout, and a good rating is 4 stars or more
set.seed(123)
scheme1 = evaluationScheme(ratingMatrix, method = "cross-validation",
                           k=5, given=-1)
```

```{r}
#We can evaluate a single or multiple models based on the defined scheme
#If "ratings" type is used, evaluations are in terms of RMSE (difference between actual and predicted rating)
results1 = evaluate(x=scheme1, method="UBCF", type="ratings")
avg(results1)
```

```{r}
#Example 2:
#Here we are splitting the data into train/test (90/10), providing 15 ratings, 
# and defining good rating (i.e. a liked item) as 3 stars or more
set.seed(123)
scheme2 = evaluationScheme(ratingMatrix, method = "split",
                           train=0.9, given=15, goodRating=3)
```

```{r}
#If type is not specified,the default "topNList" is used and evaluations are based on confusion matrix
#Using n, we are evaluating models for different values of n (number of recommendations)
results2 = evaluate(x=scheme2, method="UBCF", n = seq(10, 100, 10))
results2@results[[1]]
plot(results2, annotate=T, main="ROC Curve")
```

```{r}
############ Comparing multiple models at the same time

#Example 3:
#Defining good rating (i.e. a liked item) as 4 stars or more
set.seed(123)
scheme3 = evaluationScheme(ratingMatrix, method = "split",
                           train=0.9, given=15, goodRating=4)

#Setting up a list of models to compare
algorithms = list("random" = list(name = "RANDOM", param = NULL),
                  "UBCF_10" =   list(name = "UBCF", param = list(nn = 10)),
                  "UBCF_10_P" = list(name = "UBCF", param = list(nn = 10, method="pearson")),
                  "UBCF_25" = list(name = "UBCF", param = list(nn = 25)),
                  "IBCF_25" = list(name = "IBCF", param = list(k = 25)),
                  "IBCF_50_P" = list(name = "IBCF", param = list(k = 150, method="pearson")))

#Evaluating models in terms of their predicted ratings:
resultsRMSE = evaluate(x=scheme3, method=algorithms, type="ratings")
avg(resultsRMSE)
plot(resultsRMSE)


#Evaluating models in terms of their top_N recommended movies:
resultsROC = evaluate(x=scheme3, method=algorithms, n=seq(10,100,10))

#ROC plot
plot(resultsROC, annotate = T, legend = "topleft", main="ROC Curve")

#Precision/Recall plot
plot(resultsROC, "prec/rec", annotate = T, legend = "bottomright", main="Precision/Recall")
```

Five book recommendations to the first user in the utility matrix
```{r}
#Choose the best model and use those to make recommendation
```

Association rules analysis

```{r}
#Load the data
books.df = read.csv("Books.csv")
ratings.df = read.csv("Ratings.csv")


#remove duplicates from books dataset
books.df = books.df %>% distinct(title, .keep_all = TRUE)

#Find and Remove Dupilcates from reviews dataset
ratings.df = ratings.df %>% distinct(book_id, user_id, .keep_all = TRUE)

#Only keep users with 100 or more ratings


#Dropping all columns except Book ID and Title
books.df <- books.df %>% select(book_id, title)

#formatting the ratings dataset
ratings.df <- ratings.df %>% spread(key = book_id, value = rating)

#Remove first column (user IDs) and convert to matrix
ratings.mat = as.matrix(ratings.df[, -1])
```

```{r}
#Convert the binary incidence matrix into a transactions database
ratings.trans = as(ratings.mat, "transactions")
```

```{r}
#Inspect all existing itemsets
inspect(ratings.trans)
```

```{r}
#Plots the item frequencies (only colors with > % support or top 5)
itemFrequencyPlot(ratings.trans,support=.08)
itemFrequencyPlot(ratings.trans,topN=5)
```

```{r}
#Get rules: when running apriori(), include the minimum support, minimum confidence
rules = apriori(ratings.trans, parameter = list(supp = 0.2, conf = 0.5))
```

```{r}
#Inspect the generated rules
inspect(rules)
```

```{r}
#Let's filter by lift > 1 
#(among the rules with support>0.2 and confidence>0.5, only show the ones with lift>1)
inspect(subset(rules, lift>1)) 
```

```{r}
## Order by confidence to make it easier to understand
inspect(sort(rules, by="confidence")) 
```

```{r}
## Filter by rhs to show only the rules that have White as their consequent (right hand side)
inspect(subset(rules, rhs %in% "White"))
```

