---
title: "Predictive Analytics - Project #3"
author: "Kassandra Sellers and Clark Necciai"
date: "2024-06-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 6, fig.height = 3)
```

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(reshape2)
library(dplyr)
library(visdat)
library(arules)
library(recommenderlab)
library(RColorBrewer)

#reading in the data
books_df = read.csv("Books.csv")
ratings_df = read.csv("Ratings.csv")
```

*Initial Inspection*

```{r}
#Observe Books Data
books_df %>% glimpse()
```

```{r}
#Observe Ratings Data
ratings_df %>% glimpse()
```

### Data Preprocessing

#### Missing Values  

```{r}
#Replace "" Characters Strings with NA 
books_df[books_df$isbn == "",]$isbn <- NA
books_df[books_df$original_title == "",]$original_title <- NA
books_df[books_df$language_code == "",]$language_code <- NA

print("Books Dataframe Missingness Percentages")
#Each variable's percentage of missing values
colSums(is.na(books_df)) / nrow(books_df) * 100

print("Ratings Dataframe Missingness Percentages")
#Each variable's percentage of missing values
colSums(is.na(ratings_df)) / nrow(ratings_df) * 100
```


#### Duplicate Observations

```{r}
#Observations and Their Duplicates
duplicated = which(duplicated(books_df$title))

#Show both the original observation and any duplicates
dup_obs = books_df[which(books_df$title %in% books_df$title[duplicated]),]
dup_obs %>% select(book_id, title, authors) %>% arrange(title) %>% glimpse()
```

```{r}
#Some observations have either 2, 3, or even 4 multiple duplicates  
rows_to_remove <- dup_obs %>% 
  group_by(title) %>% 
  summarise(count = n(), 
            .groups = 'drop') %>% 
  filter(count > 1) %>% 
  summarise(total_rows_to_remove = sum(count - 1))

print(paste("Total Number of Rows to be Removed: ", rows_to_remove))
```

```{r}
#Remove Duplicates from books_df where duplicate book titles
books_df = books_df %>% distinct(title, .keep_all = TRUE)
print(paste("Number of Duplicate Entries of Books removed: ", 10000 - dim(books_df)[1]))
```

```{r}
#Remove Duplicates from ratings_df where a user rated the same book twice
ratings_df = ratings_df %>% distinct(book_id, user_id, .keep_all = TRUE)
print(paste("Number of Duplicate Entries by Users removed: ", 981756 - dim(ratings_df)[1]))
```

```{r}
#Only retain ratings for which there is a reference to in Books Dataset
ratings_df = ratings_df[which(ratings_df$book_id %in% books_df$book_id),]
print(paste("Count of Ratings removed due to not having a reference in Books:", 979478 - dim(ratings_df)[1]))
```

```{r}
#Retrieve user_id values for users with at least 100 ratings
retained_users = ratings_df %>% 
    group_by(user_id) %>%
    summarise(count_ratings = n()) %>%
    filter(count_ratings >= 100) %>% 
    distinct(user_id)

#Retain Ratings for users with at least 100 ratings
ratings_df = ratings_df[ratings_df$user_id %in% retained_users$user_id,]

#Final Dimensionality of Books Dataframe
print(paste("Final Number of Observations (Books): ", dim(books_df)[1]))

#Final Number of Observations of Ratings Dataframe
print(paste("Final Number of Observations (Ratings): ",dim(ratings_df)[1]))
```

#### Summary Statistics 

```{r}
books_df %>% summary()
```

```{r}
ratings_df %>% summary()
```

### Exploratory Data Analysis 

#### Data Visualization

```{r}
#Inspect `original_publication_year to see oldest Books
books_df[books_df$original_publication_year < 0 & !is.na(books_df$original_publication_year),] %>% 
  arrange((original_publication_year)) %>% 
  select(title, original_publication_year, authors, average_rating)
```

#### Distribution of Ratings

```{r fig.height=3, fig.width=7, message=FALSE, warning=FALSE}
#This visualization may infer that if people are hearing that a book
#is bad, they may be less inclined to read it, as evidenced by the 
#high density number of observations near the lower end of the number
#of ratings for ratings_1 and ratings_2

#Subset ratings for Density Plot
vars_to_plot <- c("ratings_1", "ratings_2", "ratings_3", "ratings_4", "ratings_5")
df_subset <- books_df[, vars_to_plot]
df_long <- melt(df_subset)

# Create density plot using ggplot
ggplot(df_long, aes(x = value, fill = variable)) +
  geom_density( alpha = 0.5) +
  theme_minimal() +
  labs(title = "Distribution of Ratings", 
       x = "Number of Ratings", 
       y = "Density",
       fill = "Rating Score")  +
  scale_x_continuous(limits = c(-50, 12500))
```

#### Highest Rated Books (title) 

```{r fig.height=2}
#See which books have the highest average ratings
books_df %>% 
  arrange(desc(average_rating)) %>% 
  select(book_id, title, average_rating, authors) %>% 
  head(5) %>%
  ggplot(aes(x = reorder(title, average_rating), y = average_rating)) +
  geom_col(aes(fill = average_rating), color = "black") +
  coord_flip() +
  geom_text(aes(label = average_rating), hjust = 1.5, color = "white") +
  labs(x = "Book Title",
       y = "Average Rating",
       title = "Top 5 Highest Rated Books") +
  theme(legend.position = "none")
```


#### Highest Rated Authors

```{r fig.height=2.5}
#Inspect Which Authors on average has the highest rated books
#We're going to be looking at authors who have written more than 
#a few books, given that the vast majority of authors have only
#written a single book

books_df %>% group_by(authors) %>%
  summarise(count_books_written = n(),
            average_rating = mean(average_rating, na.rm = T)) %>%
  filter(count_books_written >= 5) %>%
  arrange(desc(average_rating)) %>% 
  head(5) %>%
  ggplot(aes(x = reorder(authors, average_rating), y = average_rating)) +
  geom_col(aes(fill = average_rating), color = "black") +
  coord_flip() +
  geom_text(aes(label = round(average_rating,2)), hjust = 1.5, color = "white") +
  labs(x = "Authors",
       y = "Average Rating",
       title = "Top 5 Highest Rated Authors",
       subtitle = "Must have Written and Published More than Five Books") +
  theme(legend.position = "none")
```


### Recommendation System Modeling 

#### Create Utility Matrix

```{r}
#Dimensionality of Sparse Matrix
count_unique_users <- ratings_df$user_id %>% n_distinct()
count_unique_books <- ratings_df$book_id %>% n_distinct()
print(paste("Unique Users Considered:", count_unique_users))
print(paste("Unique Books Considered:", count_unique_books))

#Sparsity of Matrix
perc = 100 * dim(ratings_df)[1] / (count_unique_users * count_unique_books)
print(paste("Matrix Percentage with Ratings: ", round(perc, 2) ))
```

```{r}
#Creating utility matrix (users as rows, movies as columns, ratings as entries)
ratingmat = spread(select(ratings_df, user_id, book_id, rating), book_id, rating)
ratingmat = as.matrix(ratingmat[,-1])

#Set Row and Column Labels to be respective User Ids and Book Titles
user_labels = sort(unique(ratings_df$user_id))
book_titles = books_df[match(as.numeric(colnames(ratingmat)),books_df$book_id),]$title
dimension_names = list(user_id = user_labels, book_id = book_titles)
#Replace Book Ids with Book Titles
dimnames(ratingmat) = dimension_names
ratingmat[1:5,1:3]
```

#### Utility Matrix Visualization and Exploration

```{r fig.height=5, fig.width=8}
#Converting rating/utility matrix to realRatingMatrix to use with recommenderlab functions
ratingMatrix = as(ratingmat, "realRatingMatrix")
#Inspection of rating matrix: It appears as though that as we get further into the database, books that were added
#last had fewer ratings as a whole. As book id >> then num ratings gets fewer
#Visual inspection of a small portion of the rating matrix (first 50 users, first 100 books)
image(ratingMatrix[1:nrow(ratingMatrix),1:ncol(ratingMatrix)], main = "Raw Ratings")
```

```{r}
#Number of submitted reviews - Right Skewed (Sudden Rise around 180-195)
count_ratings = rowCounts(ratingMatrix[1:nrow(ratingMatrix),])
med_num_ratings = median(count_ratings, na.rm = T)
hist(count_ratings, breaks = 15, main = "Distribution of Submitted Ratings")
mtext((paste("Median Number of Submitted Ratings: ", med_num_ratings)),
      side = 3, line = .8, cex = 0.8)
abline(v = med_num_ratings, col = "red", lty = 2)
```


```{r fig.width=8}
#Group Visualizations
par(mfrow = c(1,2))

#Average Rating of Each User
avg_user_rating = rowMeans(ratingMatrix[,])
median_rating = median(avg_user_rating)
hist(avg_user_rating, main = "Average Rating by All Users", xlab = "Average Rating")
mtext((paste("Median Rating by All Users: ", round(median_rating,2 ))),
      side = 3, line = .7, cex = 0.7)
abline(v = median_rating, col = "red", lty = 2)

#Average Rating of Each Book
avg_book_rating = colMeans(ratingMatrix[,1:ncol(ratingMatrix)], na.rm = T)
median_rating = median(avg_book_rating)
hist(avg_book_rating, main = "Average Rating of All Books", xlab = "Average Rating")
mtext((paste("Median Rating of All Books: ", round(median_rating,2 ))),
      side = 3, line = .7, cex = 0.7)
abline(v = median_rating, col = "red", lty = 2)
```

## Modeling

### User and Item based Collaborative Filtering

```{r}
#Defining good rating as 4 stars or more
set.seed(42)
scheme = evaluationScheme(ratingMatrix,method = "split",
                           train=0.9, given=-10, goodRating=4)

#Setting up a list of models to compare
algorithms = list("random" = list(name = "RANDOM", param = NULL),
                  #User-based Collaborative Filtering Models
                  "UBCF_10" =   list(name = "UBCF", param = list(nn = 10)),
                  "UBCF_10_P" = list(name = "UBCF", param = list(nn = 10, method="pearson")),
                  "UBCF_25" = list(name = "UBCF", param = list(nn = 25)),
                  "UBCF_25_P" = list(name = "UBCF", param = list(nn = 25, method="pearson")),
                  #Item-Based Collaborative Filtering Models
                  "IBCF_10" =   list(name = "IBCF", param = list(k = 10)),
                  "IBCF_10_P" = list(name = "IBCF", param = list(k = 10, method="pearson")),                  
                  "IBCF_25" = list(name = "IBCF", param = list(k = 25)),
                  "IBCF_25_P" = list(name = "IBCF", param = list(k = 25, method="pearson")))

#Evaluating models in terms of their top_N recommended books:
resultsROC = evaluate(x=scheme, method=algorithms, n=seq(5,20,5))
```

#### Performance Evaluation 

```{r fig.height=4, fig.width=7}
#Results based on ROC - Using Top N Recommendations
plot(resultsROC, annotate = T, legend = "topleft")
title(main = "ROC Curve")
```

```{r fig.height=4, fig.width=6}
#Precision/Recall plot
plot(resultsROC, "prec/rec", annotate = T, legend = "bottomright")
title(main = "Precision vs. Recall")
```


*Overall Best Model: Item-Based Collaborative Filtering with K=25 & Pearson Correlation*


#### Predict Top 5 Books With Best UCBF and ICBF Models

```{r}
#Choose the best model and use those to make recommendation

#Best Overall IBCF Model w/ k = 25; similarity = pearson
ICBF_25_P = Recommender(ratingMatrix[-1,],"IBCF",
                    param = list(method="pearson",k = 25))

#Best Overall UBCF Model w/ nn=10; similarity = pearson
UBCF_10_P = Recommender(ratingMatrix[-1,],"UBCF",
                    param = list(method="pearson",nn = 10))

#Make Predictions
pred_ICBF_25_P = predict(ICBF_25_P,ratingMatrix[1,],n=5)
pred_ICBF_25_P_vals = predict(ICBF_25_P,ratingMatrix[1,],type="ratings")

pred_UBCF_10_P = predict(UBCF_10_P,ratingMatrix[1,],n=5)
pred_UBCF_10_P_vals = predict(UBCF_10_P,ratingMatrix[1,],type="ratings")
```

#### Compare Book Recommendation Overlap

```{r}
#Retrieve the Top 5 Recommendations and Their Rated Values for ICBF Model
as(pred_ICBF_25_P_vals,'list')$`0` %>% 
  as.data.frame() %>% 
  rename("Ratings" = ".") %>% 
  arrange(desc(Ratings)) %>% head(5)
```

```{r}
#Retrieve the Top 5 Recommendations and Their Rated Values for UCBF Model
as(pred_UBCF_10_P_vals,'list')$`0` %>% 
  as.data.frame() %>% 
  rename("Ratings" = ".") %>% 
  arrange(desc(Ratings)) %>% head(5)
```

### Association Rules Analysis

```{r}
#Now the interpretation is "Has this User Read this Book?"
association_mat <- ratingmat 

#Set all NA Values to 0
association_mat[is.na(association_mat)] <- 0

#Set all non-zero values to 1
association_mat[association_mat != 0] <- 1

#Convert the binary incidence matrix into a transactions database
book_trans = as(association_mat, "transactions")
```

### Show Highest Occurrence of All Books

```{r fig.height=5, fig.width=12}
itemFrequencyPlot(book_trans, topN=5, type="absolute", 
                  col=brewer.pal(8, 'Pastel1'),
                  main="Top Occurring Books", 
                  xlab="Absolute Item Frequency",
                  horiz=T)
```

### Inspect Top 3 Rules 

```{r}
#Get rules: when running apriori(), include the minimum support, minimum confidence
rules = apriori(book_trans, parameter = list(supp = 0.046, conf = 1), target = "rules")
```


```{r}
#List the top 3 rules sorted by lift
assoc.rules <- inspect(head(sort(rules,by="lift"),3))
```

